import { Router } from 'express';
import { z } from 'zod';
import { parse } from 'csv-parse/sync';
import fs from 'fs/promises';
import { storage } from '../../storage-wrapper';
import {
  requirePermission,
  requireOwnershipPermission,
} from '../../middleware/auth';
import { logger } from '../../middleware/logger';
import { upload } from '../../middleware/uploads';
import { QueryOptimizer } from '../../performance/query-optimizer';
import { insertSandwichCollectionSchema } from '@shared/schema';

const collectionsRouter = Router();

// Sandwich Collections Stats - Complete totals including individual + group collections (Optimized)
collectionsRouter.get('/stats', async (req, res) => {
  try {
    const stats = await QueryOptimizer.getCachedQuery(
      'sandwich-collections-stats',
      async () => {
        const collections = await storage.getAllSandwichCollections();

        let individualTotal = 0;
        let groupTotal = 0;

        collections.forEach((collection) => {
          individualTotal += collection.individualSandwiches || 0;

          // Calculate group total using standardized method: groupCollections JSONB with fallback to legacy columns
          let collectionGroupTotal = 0;

          // Primary: Use groupCollections JSONB array if available and non-empty
          if (
            collection.groupCollections &&
            Array.isArray(collection.groupCollections) &&
            collection.groupCollections.length > 0
          ) {
            collectionGroupTotal = collection.groupCollections.reduce(
              (sum, group) => {
                return sum + (group.count || 0);
              },
              0
            );
          }
          // Fallback: Use legacy group1Count + group2Count for older records
          else {
            collectionGroupTotal =
              (collection.group1Count || 0) + (collection.group2Count || 0);
          }

          groupTotal += collectionGroupTotal;
        });

        // Data recovery completed: 148,907 sandwiches recovered, exceeding the 50K adjustment
        // Removing temporary adjustment since actual missing data was recovered

        return {
          totalEntries: collections.length,
          individualSandwiches: individualTotal,
          groupSandwiches: groupTotal,
          completeTotalSandwiches: individualTotal + groupTotal,
        };
      },
      60000 // Cache for 1 minute since this data doesn't change frequently
    );

    res.json(stats);
  } catch (error) {
    res
      .status(500)
      .json({ message: 'Failed to fetch sandwich collection stats' });
  }
});

// Sandwich Collections
collectionsRouter.get('/', async (req, res) => {
  try {
    const page = parseInt(req.query.page as string) || 1;
    const limit = parseInt(req.query.limit as string) || 50;
    const offset = (page - 1) * limit;
    const sortField = (req.query.sort as string) || 'collectionDate';
    const sortOrder = (req.query.order as string) || 'desc';

    const result = await storage.getSandwichCollections(
      limit,
      offset,
      sortField,
      sortOrder
    );
    const totalCount = await storage.getSandwichCollectionsCount();

    res.json({
      collections: result,
      pagination: {
        page,
        limit,
        total: totalCount,
        totalPages: Math.ceil(totalCount / limit),
        hasNext: page < Math.ceil(totalCount / limit),
        hasPrev: page > 1,
      },
    });
  } catch (error) {
    res.status(500).json({ message: 'Failed to fetch sandwich collections' });
  }
});

collectionsRouter.post(
  '/',
  requirePermission('COLLECTIONS_ADD'),
  async (req, res) => {
    try {
      // CRITICAL BUG FIX: Handle unlimited groups using new JSONB column
      let processedBody = { ...req.body };

      // If groupCollections array is provided, store all groups in JSONB column
      if (
        req.body.groupCollections &&
        Array.isArray(req.body.groupCollections)
      ) {
        const groups = req.body.groupCollections;

        // Store ALL groups in the new JSONB column
        processedBody.groupCollections = groups;

        // Also set first two groups in legacy format for backward compatibility
        if (groups.length > 0) {
          processedBody.group1Name = groups[0].name || '';
          processedBody.group1Count = groups[0].count || 0;
        }
        if (groups.length > 1) {
          processedBody.group2Name = groups[1].name || '';
          processedBody.group2Count = groups[1].count || 0;
        }
      }

      const collectionData =
        insertSandwichCollectionSchema.parse(processedBody);

      // Add user attribution to the collection
      const user = req.user || req.session?.user;
      const enrichedCollectionData = {
        ...collectionData,
        createdBy: user?.id || 'unknown',
        createdByName:
          user?.firstName && user?.lastName
            ? `${user.firstName} ${user.lastName}`
            : user?.email || 'Unknown User',
      };

      const collection = await storage.createSandwichCollection(
        enrichedCollectionData
      );

      // Invalidate cache when new collection is created
      QueryOptimizer.invalidateCache('sandwich-collections');
      QueryOptimizer.invalidateCache('sandwich-collections-stats');

      res.status(201).json(collection);
    } catch (error) {
      if (error instanceof z.ZodError) {
        logger.warn('Invalid sandwich collection input', {
          error: error.errors,
          ip: req.ip,
        });
        res
          .status(400)
          .json({ message: 'Invalid collection data', errors: error.errors });
      } else {
        logger.error('Failed to create sandwich collection', error);
        res.status(500).json({ message: 'Failed to create collection' });
      }
    }
  }
);

// GET individual sandwich collection by ID
collectionsRouter.get('/:id', async (req, res) => {
  try {
    const id = parseInt(req.params.id);
    if (isNaN(id)) {
      return res.status(400).json({ message: 'Invalid collection ID' });
    }

    const collection = await storage.getSandwichCollectionById(id);
    if (!collection) {
      return res.status(404).json({ message: 'Collection not found' });
    }

    res.json(collection);
  } catch (error) {
    logger.error('Failed to fetch sandwich collection', error);
    res.status(500).json({ message: 'Failed to fetch collection' });
  }
});

collectionsRouter.put(
  '/:id',
  requireOwnershipPermission(
    'COLLECTIONS_EDIT_OWN',
    'COLLECTIONS_EDIT_ALL',
    async (req) => {
      const id = parseInt(req.params.id);
      const collection = await storage.getSandwichCollectionById(id);
      return collection?.userId || null;
    }
  ),
  async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      const updates = req.body;
      const collection = await storage.updateSandwichCollection(id, updates);
      if (!collection) {
        return res.status(404).json({ message: 'Collection not found' });
      }

      // Invalidate cache when collection is updated
      QueryOptimizer.invalidateCache('sandwich-collections');

      res.json(collection);
    } catch (error) {
      logger.error('Failed to update sandwich collection', error);
      res.status(400).json({ message: 'Invalid update data' });
    }
  }
);

// Fix data corruption in sandwich collections - MUST be before /:id route
collectionsRouter.patch(
  '/fix-data-corruption',
  requirePermission('COLLECTIONS_EDIT_ALL'),
  async (req, res) => {
    try {
      const collections = await storage.getAllSandwichCollections();
      let fixedCount = 0;
      const fixes = [];

      for (const collection of collections) {
        let needsUpdate = false;
        const updates: any = {};
        const fixType = [];

        // PHASE 5: Check group collections using new column structure
        const individual = Number(collection.individualSandwiches) || 0;
        const groupTotal =
          (collection.group1Count || 0) + (collection.group2Count || 0);

        // Fix 1: Check if individual count equals group total (duplication issue)
        if (individual > 0 && groupTotal > 0 && individual === groupTotal) {
          updates.individualSandwiches = 0;
          needsUpdate = true;
          fixType.push('removed duplicate individual count');
        }

        // Fix 2: Check if host name is "Groups" with individual count but no group data
        if (
          (collection.hostName === 'Groups' ||
            collection.hostName === 'groups') &&
          individual > 0 &&
          groupTotal === 0
        ) {
          // Move individual count to group data
          const newGroupData = [
            {
              name: 'Group',
              count: individual,
              groupName: 'Group',
              sandwichCount: individual,
            },
          ];
          updates.individualSandwiches = 0;
          updates.groupCollections = JSON.stringify(newGroupData);
          needsUpdate = true;
          fixType.push('moved individual count to group data for Groups entry');
        }

        if (needsUpdate) {
          try {
            await storage.updateSandwichCollection(collection.id, updates);
            fixedCount++;
            fixes.push({
              id: collection.id,
              hostName: collection.hostName,
              originalIndividual: individual,
              originalGroup: groupTotal,
              newIndividual:
                updates.individualSandwiches !== undefined
                  ? updates.individualSandwiches
                  : individual,
              newGroupData:
                updates.groupCollections || collection.groupCollections,
              fixType: fixType.join(', '),
            });
          } catch (updateError) {
            logger.warn(
              `Failed to fix collection ${collection.id}:`,
              updateError
            );
          }
        }
      }

      res.json({
        message: `Successfully fixed ${fixedCount} data corruption issues`,
        fixedCount,
        totalChecked: collections.length,
        fixes: fixes.slice(0, 10), // Return first 10 fixes for review
      });
    } catch (error) {
      logger.error('Failed to fix data corruption:', error);
      res.status(500).json({ message: 'Failed to fix data corruption' });
    }
  }
);

collectionsRouter.patch(
  '/:id',
  requireOwnershipPermission(
    'COLLECTIONS_EDIT_OWN',
    'COLLECTIONS_EDIT_ALL',
    async (req) => {
      const id = parseInt(req.params.id);
      const collection = await storage.getSandwichCollectionById(id);
      return collection?.userId || null;
    }
  ),
  async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      if (isNaN(id)) {
        return res.status(400).json({ message: 'Invalid collection ID' });
      }

      const updates = req.body;
      const collection = await storage.updateSandwichCollection(id, updates);
      if (!collection) {
        return res.status(404).json({ message: 'Collection not found' });
      }

      // Invalidate cache when collection is updated
      QueryOptimizer.invalidateCache('sandwich-collections');

      res.json(collection);
    } catch (error) {
      logger.error('Failed to patch sandwich collection', error);
      res.status(500).json({ message: 'Failed to update collection' });
    }
  }
);

collectionsRouter.delete('/bulk', async (req, res) => {
  try {
    const collections = await storage.getAllSandwichCollections();
    const collectionsToDelete = collections.filter((collection) => {
      const hostName = collection.hostName;
      return hostName.startsWith('Loc ') || /^Group [1-8]/.test(hostName);
    });

    let deletedCount = 0;
    // Delete in reverse order by ID to maintain consistency
    const sortedCollections = collectionsToDelete.sort((a, b) => b.id - a.id);

    for (const collection of sortedCollections) {
      try {
        const deleted = await storage.deleteSandwichCollection(collection.id);
        if (deleted) {
          deletedCount++;
        }
      } catch (error) {
        console.error(`Failed to delete collection ${collection.id}:`, error);
      }
    }

    res.json({
      message: `Successfully deleted ${deletedCount} duplicate entries`,
      deletedCount,
      patterns: ['Loc *', 'Group 1-8'],
    });
  } catch (error) {
    logger.error('Failed to bulk delete sandwich collections', error);
    res.status(500).json({ message: 'Failed to delete duplicate entries' });
  }
});

// DELETE individual collection
collectionsRouter.delete(
  '/:id',
  requirePermission('COLLECTIONS_DELETE'),
  async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      if (isNaN(id)) {
        return res.status(400).json({ message: 'Invalid collection ID' });
      }

      const deleted = await storage.deleteSandwichCollection(id);
      if (!deleted) {
        return res.status(404).json({ message: 'Collection not found' });
      }

      // Invalidate cache when collection is deleted
      QueryOptimizer.invalidateCache('sandwich-collections');

      res.status(204).send();
    } catch (error) {
      logger.error('Failed to delete sandwich collection', error);
      res.status(500).json({ message: 'Failed to delete collection' });
    }
  }
);

// Analyze duplicates in sandwich collections
collectionsRouter.get('/analyze-duplicates', async (req, res) => {
  try {
    const collections = await storage.getAllSandwichCollections();

    // Group by date, host, and sandwich counts to find exact duplicates
    const duplicateGroups = new Map();
    const suspiciousPatterns = [];
    const ogDuplicates = [];

    collections.forEach((collection) => {
      const key = `${collection.collectionDate}-${collection.hostName}-${collection.individualSandwiches}-${collection.groupCollections}`;

      if (!duplicateGroups.has(key)) {
        duplicateGroups.set(key, []);
      }
      duplicateGroups.get(key).push(collection);

      // Check for suspicious patterns - ONLY truly problematic entries
      const hostName = (collection.hostName || '').toLowerCase().trim();
      if (
        hostName.startsWith('loc ') ||
        hostName.match(/^group \d+(-\d+)?$/) ||
        hostName.match(/^loc\d+$/) ||
        hostName === 'test' ||
        hostName.includes('test') ||
        hostName.includes('duplicate') ||
        hostName.includes('unknown') ||
        hostName.includes('no location') ||
        hostName === '' ||
        hostName === 'null' ||
        // Check for obviously incorrect host names
        hostName.length < 3 ||
        hostName.match(/^\d+$/) || // Pure numbers
        hostName.match(/^[a-z]{1,2}$/) // Single/double letters
      ) {
        suspiciousPatterns.push(collection);
      }
    });

    // Find OG Sandwich Project duplicates with early collections
    const ogCollections = collections.filter(
      (c) => c.hostName === 'OG Sandwich Project'
    );
    const earlyCollections = collections.filter(
      (c) =>
        c.hostName !== 'OG Sandwich Project' &&
        (c.hostName === '' ||
          c.hostName === null ||
          c.hostName.trim() === '' ||
          c.hostName.toLowerCase().includes('unknown') ||
          c.hostName.toLowerCase().includes('no location'))
    );

    const ogMap = new Map();
    ogCollections.forEach((og) => {
      const key = `${og.collectionDate}-${og.individualSandwiches}`;
      if (!ogMap.has(key)) {
        ogMap.set(key, []);
      }
      ogMap.get(key).push(og);
    });

    earlyCollections.forEach((early) => {
      const key = `${early.collectionDate}-${early.individualSandwiches}`;
      if (ogMap.has(key)) {
        const ogEntries = ogMap.get(key);
        ogDuplicates.push({
          ogEntry: ogEntries[0],
          earlyEntry: early,
          reason: 'Same date and sandwich count as OG Project entry',
        });
      }
    });

    // Also find duplicate OG entries
    ogMap.forEach((ogGroup) => {
      if (ogGroup.length > 1) {
        const sorted = ogGroup.sort(
          (a, b) =>
            new Date(b.submittedAt).getTime() -
            new Date(a.submittedAt).getTime()
        );
        sorted.slice(1).forEach((duplicate) => {
          ogDuplicates.push({
            ogEntry: sorted[0],
            duplicateOgEntry: duplicate,
            reason: 'Duplicate OG Project entry',
          });
        });
      }
    });

    // Find actual duplicates (groups with more than 1 entry)
    const duplicates = Array.from(duplicateGroups.values())
      .filter((group) => group.length > 1)
      .map((group) => ({
        entries: group,
        count: group.length,
        keepNewest: group.sort(
          (a, b) =>
            new Date(b.submittedAt).getTime() -
            new Date(a.submittedAt).getTime()
        )[0],
        toDelete: group.slice(1),
      }));

    res.json({
      totalCollections: collections.length,
      duplicateGroups: duplicates.length,
      totalDuplicateEntries: duplicates.reduce(
        (sum, group) => sum + group.toDelete.length,
        0
      ),
      suspiciousPatterns: suspiciousPatterns.length,
      ogDuplicates: ogDuplicates.length,
      duplicates,
      suspiciousEntries: suspiciousPatterns,
      ogDuplicateEntries: ogDuplicates,
    });
  } catch (error) {
    logger.error('Failed to analyze duplicates', error);
    res.status(500).json({ message: 'Failed to analyze duplicates' });
  }
});

// Clean selected suspicious entries from sandwich collections
collectionsRouter.delete(
  '/clean-selected',
  requirePermission('DATA_EXPORT'),
  async (req, res) => {
    try {
      const { ids } = req.body;

      if (!Array.isArray(ids) || ids.length === 0) {
        return res.status(400).json({ message: 'Invalid or empty IDs array' });
      }

      let deletedCount = 0;
      for (const id of ids) {
        try {
          await storage.deleteSandwichCollection(id);
          deletedCount++;
        } catch (error) {
          logger.warn(`Failed to delete collection ${id}:`, error);
        }
      }

      res.json({
        message: `Successfully deleted ${deletedCount} selected entries`,
        deletedCount,
      });
    } catch (error) {
      logger.error('Failed to delete selected suspicious entries:', error);
      res.status(500).json({ message: 'Failed to delete selected entries' });
    }
  }
);

// Clean duplicates from sandwich collections
collectionsRouter.delete(
  '/clean-duplicates',
  requirePermission('DATA_EXPORT'),
  async (req, res) => {
    try {
      const { mode = 'exact' } = req.body; // 'exact', 'suspicious', or 'og-duplicates'
      const collections = await storage.getAllSandwichCollections();

      let collectionsToDelete = [];

      if (mode === 'exact') {
        // Find exact duplicates based on date, host, and counts
        const duplicateGroups = new Map();

        collections.forEach((collection) => {
          const key = `${collection.collectionDate}-${collection.hostName}-${collection.individualSandwiches}-${collection.groupCollections}`;

          if (!duplicateGroups.has(key)) {
            duplicateGroups.set(key, []);
          }
          duplicateGroups.get(key).push(collection);
        });

        // Keep only the newest entry from each duplicate group
        duplicateGroups.forEach((group) => {
          if (group.length > 1) {
            const sorted = group.sort(
              (a, b) =>
                new Date(b.submittedAt).getTime() -
                new Date(a.submittedAt).getTime()
            );
            collectionsToDelete.push(...sorted.slice(1)); // Keep first (newest), delete rest
          }
        });
      } else if (mode === 'suspicious') {
        // Remove entries with suspicious patterns (improved detection)
        collectionsToDelete = collections.filter((collection) => {
          const hostName = (collection.hostName || '').toLowerCase().trim();
          return (
            hostName.startsWith('loc ') ||
            hostName.startsWith('group ') ||
            hostName.match(/^group \d+(-\d+)?$/) ||
            hostName.match(/^loc\d+$/) ||
            hostName === 'groups' ||
            hostName === 'test' ||
            hostName.includes('test') ||
            hostName.includes('duplicate') ||
            hostName.includes('unknown') ||
            hostName.includes('no location') ||
            hostName === '' ||
            hostName === 'null' ||
            // Check for obviously incorrect host names
            hostName.length < 3 ||
            hostName.match(/^\d+$/) || // Pure numbers
            hostName.match(/^[a-z]{1,2}$/) // Single/double letters
          );
        });
      }

      let deletedCount = 0;
      const errors = [];

      // Delete in reverse order by ID to maintain consistency
      const sortedCollections = collectionsToDelete.sort((a, b) => b.id - a.id);

      for (const collection of sortedCollections) {
        try {
          // Ensure ID is a valid number
          const id = Number(collection.id);
          if (isNaN(id)) {
            errors.push(`Invalid collection ID: ${collection.id}`);
            continue;
          }

          const deleted = await storage.deleteSandwichCollection(id);
          if (deleted) {
            deletedCount++;
          }
        } catch (error) {
          const errorMessage =
            error instanceof Error ? error.message : 'Unknown error';
          errors.push(
            `Failed to delete collection ${collection.id}: ${errorMessage}`
          );
          console.error(`Failed to delete collection ${collection.id}:`, error);
        }
      }

      res.json({
        message: `Successfully cleaned ${deletedCount} duplicate entries using ${mode} mode`,
        deletedCount,
        totalFound: collectionsToDelete.length,
        errors: errors.length > 0 ? errors.slice(0, 5) : undefined,
        mode,
      });
    } catch (error) {
      logger.error('Failed to clean duplicates', error);
      res.status(500).json({ message: 'Failed to clean duplicate entries' });
    }
  }
);

// Batch delete sandwich collections (must be before :id route)
collectionsRouter.delete('/batch-delete', async (req, res) => {
  try {
    const { ids } = req.body;

    if (!Array.isArray(ids) || ids.length === 0) {
      return res.status(400).json({ message: 'Invalid or empty IDs array' });
    }

    let deletedCount = 0;
    const errors = [];

    // Delete in reverse order to maintain consistency
    const sortedIds = ids.sort((a, b) => b - a);

    for (const id of sortedIds) {
      try {
        const deleted = await storage.deleteSandwichCollection(id);
        if (deleted) {
          deletedCount++;
        } else {
          errors.push(`Collection with ID ${id} not found`);
        }
      } catch (error) {
        errors.push(
          `Failed to delete collection ${id}: ${
            error instanceof Error ? error.message : 'Unknown error'
          }`
        );
      }
    }

    res.json({
      message: `Successfully deleted ${deletedCount} of ${ids.length} collections`,
      deletedCount,
      totalRequested: ids.length,
      errors: errors.length > 0 ? errors.slice(0, 5) : undefined,
    });
  } catch (error) {
    logger.error('Failed to batch delete collections', error);
    res.status(500).json({ message: 'Failed to batch delete collections' });
  }
});

// Batch edit sandwich collections
collectionsRouter.patch(
  '/batch-edit',
  requirePermission('DATA_EXPORT'),
  async (req, res) => {
    try {
      const { ids, updates } = req.body;

      if (!Array.isArray(ids) || ids.length === 0) {
        return res.status(400).json({ message: 'Invalid or empty IDs array' });
      }

      if (!updates || Object.keys(updates).length === 0) {
        return res.status(400).json({ message: 'No updates provided' });
      }

      let updatedCount = 0;
      const errors = [];

      for (const id of ids) {
        try {
          const updated = await storage.updateSandwichCollection(id, updates);
          if (updated) {
            updatedCount++;
          } else {
            errors.push(`Collection with ID ${id} not found`);
          }
        } catch (error) {
          errors.push(
            `Failed to update collection ${id}: ${
              error instanceof Error ? error.message : 'Unknown error'
            }`
          );
        }
      }

      res.json({
        message: `Successfully updated ${updatedCount} of ${ids.length} collections`,
        updatedCount,
        totalRequested: ids.length,
        errors: errors.length > 0 ? errors.slice(0, 5) : undefined,
      });
    } catch (error) {
      logger.error('Failed to batch edit collections', error);
      res.status(500).json({ message: 'Failed to batch edit collections' });
    }
  }
);

export default collectionsRouter;
